{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classiflow End-to-End Reproducible Notebook\n",
        "## MR Spectroscopy MB Molecular Group Classification (Meta, Sklearn)\n",
        "\n",
        "## 0. Title + Reviewer-Friendly Overview\n",
        "\n",
        "Classiflow provides reproducible, artifact-traceable ML workflows for technical validation and deployment gating. This notebook demonstrates a **technical-validation-only** workflow for medulloblastoma (MB) molecular group classification from MR spectroscopy features.\n",
        "\n",
        "Scope of this notebook:\n",
        "- Train/validate with nested CV using Classiflow `project run-technical`.\n",
        "- Summarize technical artifacts (metrics, inner/outer CV outputs, lineage, resolved config).\n",
        "- Evaluate the **Research / Exploratory Gate** on technical results.\n",
        "\n",
        "Important study note:\n",
        "- This dataset setup has **no independent test manifest** configured.\n",
        "- Therefore, this notebook reports **technical validation status only** and explicitly does not claim independent-test promotion readiness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestamp: 2026-02-09T12:38:34.347049\n",
            "Python: 3.11.10\n",
            "Platform: macOS-15.7.3-x86_64-i386-64bit\n",
            "Classiflow: 0.1.0\n",
            "NumPy: 1.26.4\n",
            "Pandas: 2.2.3\n",
            "Matplotlib: 3.9.2\n",
            "scikit-learn: 1.5.2\n",
            "Git commit: 813b91f311739b7591817da6b390d18ff53653c6\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# os.environ.setdefault(\"MPLBACKEND\", \"Agg\")\n",
        "\n",
        "import hashlib\n",
        "import json\n",
        "import platform\n",
        "import random\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "\n",
        "from classiflow import __version__ as classiflow_version\n",
        "from classiflow.projects.project_models import ProjectConfig, ThresholdsConfig\n",
        "from classiflow.projects.promotion_templates import get_promotion_gate_template\n",
        "from classiflow.projects.promotion import resolve_metric\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "print(f\"Classiflow: {classiflow_version}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")\n",
        "print(f\"Matplotlib: {matplotlib.__version__}\")\n",
        "\n",
        "try:\n",
        "    import sklearn\n",
        "    print(f\"scikit-learn: {sklearn.__version__}\")\n",
        "except Exception as exc:\n",
        "    print(f\"scikit-learn version unavailable: {exc}\")\n",
        "\n",
        "try:\n",
        "    git_hash = subprocess.run([\"git\", \"rev-parse\", \"HEAD\"], capture_output=True, text=True, check=False).stdout.strip()\n",
        "    print(f\"Git commit: {git_hash if git_hash else 'unavailable'}\")\n",
        "except Exception:\n",
        "    print(\"Git commit: unavailable\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (94, 28)\n",
            "Feature columns: 27\n",
            "Classes: ['G3', 'G4', 'SHH', 'WNT']\n",
            "Top missingness rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missing_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MOLECULAR</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ala_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tIns_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tCr_conc.tCho_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tCr_conc.Glx_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tCr_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tCho_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tau_conc.tCho_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tau_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scyllo_conc</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    missing_pct\n",
              "MOLECULAR                   0.0\n",
              "Ala_conc                    0.0\n",
              "tIns_conc                   0.0\n",
              "tCr_conc.tCho_conc          0.0\n",
              "tCr_conc.Glx_conc           0.0\n",
              "tCr_conc                    0.0\n",
              "tCho_conc                   0.0\n",
              "Tau_conc.tCho_conc          0.0\n",
              "Tau_conc                    0.0\n",
              "Scyllo_conc                 0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label leakage heuristic check: PASS\n"
          ]
        }
      ],
      "source": [
        "TRAIN_CSV = Path(\"../data/MBmerged-z-scores_MLready_correction.csv\")\n",
        "LABEL_COL = \"MOLECULAR\"\n",
        "\n",
        "if not TRAIN_CSV.exists():\n",
        "    raise FileNotFoundError(f\"Training dataset not found: {TRAIN_CSV}\")\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "if LABEL_COL not in train_df.columns:\n",
        "    raise ValueError(f\"Missing required label column: {LABEL_COL}\")\n",
        "\n",
        "feature_cols = [c for c in train_df.columns if c != LABEL_COL]\n",
        "if not feature_cols:\n",
        "    raise ValueError(\"No feature columns found after excluding label column\")\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Feature columns: {len(feature_cols)}\")\n",
        "print(f\"Classes: {sorted(train_df[LABEL_COL].dropna().unique().tolist())}\")\n",
        "\n",
        "missing_summary = pd.DataFrame({\n",
        "    \"missing_pct\": train_df.isna().mean().mul(100).round(3)\n",
        "}).sort_values(\"missing_pct\", ascending=False)\n",
        "\n",
        "print(\"Top missingness rows:\")\n",
        "display(missing_summary.head(10))\n",
        "\n",
        "leakage_tokens = (\"label\", \"class\", \"target\", \"outcome\", \"y_\")\n",
        "suspicious = [\n",
        "    c for c in train_df.columns\n",
        "    if c != LABEL_COL and any(tok in c.lower() for tok in leakage_tokens)\n",
        "]\n",
        "assert not suspicious, (\n",
        "    \"Potential label leakage columns detected (heuristic). \"\n",
        "    f\"Please review/remove before training: {suspicious}\"\n",
        ")\n",
        "print(\"Label leakage heuristic check: PASS\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Distributions (Reviewer-Facing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percent</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MOLECULAR</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>G3</th>\n",
              "      <td>22</td>\n",
              "      <td>23.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G4</th>\n",
              "      <td>35</td>\n",
              "      <td>37.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SHH</th>\n",
              "      <td>26</td>\n",
              "      <td>27.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WNT</th>\n",
              "      <td>11</td>\n",
              "      <td>11.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count  percent\n",
              "MOLECULAR                \n",
              "G3            22    23.40\n",
              "G4            35    37.23\n",
              "SHH           26    27.66\n",
              "WNT           11    11.70"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qw/wt3crg911d32djy9xk8j0q8r0000gn/T/ipykernel_74743/4029106374.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "class_counts = train_df[LABEL_COL].value_counts().sort_index()\n",
        "class_props = (class_counts / class_counts.sum() * 100).round(2)\n",
        "\n",
        "summary_table = pd.DataFrame({\n",
        "    \"count\": class_counts,\n",
        "    \"percent\": class_props,\n",
        "})\n",
        "display(summary_table)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4), constrained_layout=True)\n",
        "class_counts.plot(kind=\"bar\", ax=ax)\n",
        "ax.set_title(\"Train Class Counts\")\n",
        "ax.set_xlabel(\"Class\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.tick_params(axis=\"x\", rotation=45)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create / Display Project Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote project config: runs/mrs_mb_meta_sklearn_technical/project/project.yaml\n",
            "Wrote thresholds config: runs/mrs_mb_meta_sklearn_technical/project/registry/thresholds.yaml\n",
            "\n",
            "Requested config (YAML):\n",
            "project:\n",
            "  id: MRS_MB_META_TECH\n",
            "  name: MRS MB Meta Technical\n",
            "  description: Reviewer notebook technical-validation-only run\n",
            "  owner: local\n",
            "data:\n",
            "  train:\n",
            "    manifest: /Users/alex/Documents/project-MLSubtype/data/MBmerged-z-scores_MLready_correction.csv\n",
            "  test: null\n",
            "key_columns:\n",
            "  sample_id: null\n",
            "  patient_id: null\n",
            "  label: MOLECULAR\n",
            "  slide_id: null\n",
            "  specimen_id: null\n",
            "task:\n",
            "  mode: meta\n",
            "  patient_stratified: false\n",
            "  hierarchy_path: null\n",
            "validation:\n",
            "  nested_cv:\n",
            "    outer_folds: 3\n",
            "    inner_folds: 3\n",
            "    repeats: 1\n",
            "    seed: 42\n",
            "models:\n",
            "  candidates:\n",
            "  - logistic_regression\n",
            "  - svm\n",
            "  - random_forest\n",
            "  selection_metric: f1\n",
            "  selection_direction: max\n",
            "imbalance:\n",
            "  smote:\n",
            "    enabled: false\n",
            "    compare: false\n",
            "metrics:\n",
            "  primary:\n",
            "  - f1\n",
            "  - balanced_accuracy\n",
            "  averaging: macro\n",
            "  include_confidence_intervals: false\n",
            "calibration:\n",
            "  calibrate_meta: true\n",
            "  method: sigmoid\n",
            "  cv: 3\n",
            "  bins: 10\n",
            "  isotonic_min_samples: 100\n",
            "final_model:\n",
            "  sampler: null\n",
            "  sanity_min_std: 0.02\n",
            "  sanity_max_mean_deviation: 0.15\n",
            "  train_from_scratch: true\n",
            "  verify_dataset_hash: true\n",
            "bundle:\n",
            "  name: model_bundle\n",
            "  include_preprocessing: true\n",
            "  format: zip\n",
            "execution:\n",
            "  engine: sklearn\n",
            "\n",
            "Resolved/effective config:\n",
            "project:\n",
            "  id: MRS_MB_META_TECH\n",
            "  name: MRS MB Meta Technical\n",
            "  description: Reviewer notebook technical-validation-only run\n",
            "  owner: local\n",
            "data:\n",
            "  train:\n",
            "    manifest: /Users/alex/Documents/project-MLSubtype/data/MBmerged-z-scores_MLready_correction.csv\n",
            "key_columns:\n",
            "  label: MOLECULAR\n",
            "task:\n",
            "  mode: meta\n",
            "  patient_stratified: false\n",
            "validation:\n",
            "  nested_cv:\n",
            "    outer_folds: 3\n",
            "    inner_folds: 3\n",
            "    repeats: 1\n",
            "    seed: 42\n",
            "models:\n",
            "  candidates:\n",
            "  - logistic_regression\n",
            "  - svm\n",
            "  - random_forest\n",
            "  selection_metric: f1\n",
            "  selection_direction: max\n",
            "imbalance:\n",
            "  smote:\n",
            "    enabled: false\n",
            "    compare: false\n",
            "multiclass:\n",
            "  group_stratify: true\n",
            "  sklearn:\n",
            "    logreg:\n",
            "      solver: saga\n",
            "      multi_class: auto\n",
            "      penalty: l2\n",
            "      max_iter: 5000\n",
            "      tol: 0.001\n",
            "      C: 1.0\n",
            "      class_weight: balanced\n",
            "      n_jobs: -1\n",
            "metrics:\n",
            "  primary:\n",
            "  - f1\n",
            "  - balanced_accuracy\n",
            "  averaging: macro\n",
            "  include_confidence_intervals: false\n",
            "calibration:\n",
            "  enabled: 'true'\n",
            "  method: sigmoid\n",
            "  cv: 3\n",
            "  bins: 10\n",
            "  binning: uniform\n",
            "  isotonic_min_samples: 100\n",
            "  policy:\n",
            "    apply_to_modes:\n",
            "    - meta\n",
            "    force_keep: false\n",
            "    thresholds:\n",
            "      underconfidence_gap: -0.1\n",
            "      high_accuracy: 0.9\n",
            "      near_perfect_accuracy: 0.97\n",
            "      min_calibration_n: 200\n",
            "      min_class_n: 25\n",
            "      min_brier_improvement: 0.002\n",
            "      max_log_loss_regression: 0.01\n",
            "      max_ece_ovr_regression: 0.01\n",
            "final_model:\n",
            "  sanity_min_std: 0.02\n",
            "  sanity_max_mean_deviation: 0.15\n",
            "  train_from_scratch: true\n",
            "  verify_dataset_hash: true\n",
            "bundle:\n",
            "  name: model_bundle\n",
            "  include_preprocessing: true\n",
            "  format: zip\n",
            "execution:\n",
            "  engine: sklearn\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FAST_MODE = True\n",
        "\n",
        "if FAST_MODE:\n",
        "    outer_folds = 3\n",
        "    inner_folds = 3\n",
        "    repeats = 1\n",
        "    candidates = [\"logistic_regression\", \"svm\", \"random_forest\"]\n",
        "else:\n",
        "    outer_folds = 5\n",
        "    inner_folds = 5\n",
        "    repeats = 2\n",
        "    candidates = [\"logistic_regression\", \"svm\", \"random_forest\", \"gradient_boost\"]\n",
        "\n",
        "OUTPUT_ROOT = Path(\"runs/mrs_mb_meta_sklearn_technical\")\n",
        "PROJECT_DIR = OUTPUT_ROOT / \"project\"\n",
        "PROJECT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "(PROJECT_DIR / \"registry\").mkdir(parents=True, exist_ok=True)\n",
        "(PROJECT_DIR / \"runs\").mkdir(parents=True, exist_ok=True)\n",
        "(PROJECT_DIR / \"promotion\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "project_yaml = PROJECT_DIR / \"project.yaml\"\n",
        "thresholds_yaml = PROJECT_DIR / \"registry\" / \"thresholds.yaml\"\n",
        "labels_yaml = PROJECT_DIR / \"registry\" / \"labels.yaml\"\n",
        "features_yaml = PROJECT_DIR / \"registry\" / \"features.yaml\"\n",
        "\n",
        "project_payload = {\n",
        "    \"project\": {\n",
        "        \"id\": \"MRS_MB_META_TECH\",\n",
        "        \"name\": \"MRS MB Meta Technical\",\n",
        "        \"description\": \"Reviewer notebook technical-validation-only run\",\n",
        "        \"owner\": \"local\",\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"train\": {\"manifest\": str(TRAIN_CSV.resolve())},\n",
        "        \"test\": None,\n",
        "    },\n",
        "    \"key_columns\": {\n",
        "        \"sample_id\": None,\n",
        "        \"patient_id\": None,\n",
        "        \"label\": LABEL_COL,\n",
        "        \"slide_id\": None,\n",
        "        \"specimen_id\": None,\n",
        "    },\n",
        "    \"task\": {\n",
        "        \"mode\": \"meta\",\n",
        "        \"patient_stratified\": False,\n",
        "        \"hierarchy_path\": None,\n",
        "    },\n",
        "    \"validation\": {\n",
        "        \"nested_cv\": {\n",
        "            \"outer_folds\": outer_folds,\n",
        "            \"inner_folds\": inner_folds,\n",
        "            \"repeats\": repeats,\n",
        "            \"seed\": SEED,\n",
        "        }\n",
        "    },\n",
        "    \"models\": {\n",
        "        \"candidates\": candidates,\n",
        "        \"selection_metric\": \"f1\",\n",
        "        \"selection_direction\": \"max\",\n",
        "    },\n",
        "    \"imbalance\": {\n",
        "        \"smote\": {\n",
        "            \"enabled\": False,\n",
        "            \"compare\": False,\n",
        "        }\n",
        "    },\n",
        "    \"metrics\": {\n",
        "        \"primary\": [\"f1\", \"balanced_accuracy\"],\n",
        "        \"averaging\": \"macro\",\n",
        "        \"include_confidence_intervals\": False,\n",
        "    },\n",
        "    \"calibration\": {\n",
        "        \"calibrate_meta\": True,\n",
        "        \"method\": \"sigmoid\",\n",
        "        \"cv\": 3,\n",
        "        \"bins\": 10,\n",
        "        \"isotonic_min_samples\": 100,\n",
        "    },\n",
        "    \"final_model\": {\n",
        "        \"sampler\": None,\n",
        "        \"sanity_min_std\": 0.02,\n",
        "        \"sanity_max_mean_deviation\": 0.15,\n",
        "        \"train_from_scratch\": True,\n",
        "        \"verify_dataset_hash\": True,\n",
        "    },\n",
        "    \"bundle\": {\n",
        "        \"name\": \"model_bundle\",\n",
        "        \"include_preprocessing\": True,\n",
        "        \"format\": \"zip\",\n",
        "    },\n",
        "    \"execution\": {\n",
        "        \"engine\": \"sklearn\",\n",
        "    },\n",
        "}\n",
        "\n",
        "thresholds_payload = {\n",
        "    \"promotion_gate_template\": \"research_exploratory\",\n",
        "    \"technical_validation\": {\"required\": {}, \"safety\": {}, \"stability\": None},\n",
        "    \"independent_test\": {\"required\": {}, \"safety\": {}, \"stability\": None},\n",
        "    \"promotion\": {\"calibration\": {\"brier_max\": None, \"ece_max\": None}},\n",
        "}\n",
        "\n",
        "cfg = ProjectConfig.model_validate(project_payload)\n",
        "cfg.save(project_yaml)\n",
        "ThresholdsConfig.model_validate(thresholds_payload).save(thresholds_yaml)\n",
        "labels_yaml.write_text(\"labels: {}\\n\", encoding=\"utf-8\")\n",
        "features_yaml.write_text(\"features: {}\\n\", encoding=\"utf-8\")\n",
        "\n",
        "print(\"Wrote project config:\", project_yaml)\n",
        "print(\"Wrote thresholds config:\", thresholds_yaml)\n",
        "print(\"\\nRequested config (YAML):\")\n",
        "print(yaml.safe_dump(project_payload, sort_keys=False))\n",
        "\n",
        "print(\"Resolved/effective config:\")\n",
        "print(yaml.safe_dump(ProjectConfig.load(project_yaml).to_yaml_dict(), sort_keys=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run 1 â€” Technical Validation (Nested CV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset hash: 32311d51283f3207a485d3c1975af6ed26e40be8ad23e5d1efa4ff37f10ce243\n",
            "$ classiflow project register-dataset runs/mrs_mb_meta_sklearn_technical/project --type train --manifest ../data/MBmerged-z-scores_MLready_correction.csv\n",
            "Registered train dataset: 32311d51283f...\n",
            "\n",
            "$ classiflow project run-technical runs/mrs_mb_meta_sklearn_technical/project --run-id technical\n",
            "runs/mrs_mb_meta_sklearn_technical/project/runs/technical_validation/technical\n",
            "\n",
            "Technical artifacts mirrored to: runs/mrs_mb_meta_sklearn_technical/technical\n"
          ]
        }
      ],
      "source": [
        "def run_cmd(cmd, cwd=None):\n",
        "    print(\"$\", \" \".join(cmd))\n",
        "    out = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True)\n",
        "    if out.stdout:\n",
        "        print(out.stdout)\n",
        "    if out.returncode != 0:\n",
        "        if out.stderr:\n",
        "            print(out.stderr)\n",
        "        raise RuntimeError(f\"Command failed ({out.returncode}): {' '.join(cmd)}\")\n",
        "    return out\n",
        "\n",
        "def file_sha256(path: Path) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with path.open(\"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "print(\"Training dataset hash:\", file_sha256(TRAIN_CSV))\n",
        "\n",
        "run_cmd([\n",
        "    \"classiflow\", \"project\", \"register-dataset\", str(PROJECT_DIR),\n",
        "    \"--type\", \"train\", \"--manifest\", str(TRAIN_CSV)\n",
        "])\n",
        "\n",
        "run_cmd([\n",
        "    \"classiflow\", \"project\", \"run-technical\", str(PROJECT_DIR),\n",
        "    \"--run-id\", \"technical\"\n",
        "])\n",
        "\n",
        "TECHNICAL_RUN = PROJECT_DIR / \"runs\" / \"technical_validation\" / \"technical\"\n",
        "if not TECHNICAL_RUN.exists():\n",
        "    raise FileNotFoundError(f\"Technical run directory not found: {TECHNICAL_RUN}\")\n",
        "\n",
        "TECHNICAL_ALIAS = OUTPUT_ROOT / \"technical\"\n",
        "if TECHNICAL_ALIAS.exists() and TECHNICAL_ALIAS.is_dir():\n",
        "    shutil.rmtree(TECHNICAL_ALIAS)\n",
        "shutil.copytree(TECHNICAL_RUN, TECHNICAL_ALIAS)\n",
        "print(\"Technical artifacts mirrored to:\", TECHNICAL_ALIAS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using inner CV file: metrics_inner_cv.csv\n",
            "Technical metrics summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>specificity</th>\n",
              "      <th>ppv</th>\n",
              "      <th>npv</th>\n",
              "      <th>precision</th>\n",
              "      <th>brier_calibrated</th>\n",
              "      <th>ece_calibrated</th>\n",
              "      <th>log_loss_calibrated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.991475</td>\n",
              "      <td>0.990741</td>\n",
              "      <td>0.990741</td>\n",
              "      <td>0.996032</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.996528</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.021838</td>\n",
              "      <td>0.213387</td>\n",
              "      <td>0.257075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   f1_macro  balanced_accuracy    recall  specificity       ppv       npv  \\\n",
              "0  0.991475           0.990741  0.990741     0.996032  0.993056  0.996528   \n",
              "\n",
              "   precision  brier_calibrated  ece_calibrated  log_loss_calibrated  \n",
              "0   0.993056          0.021838        0.213387             0.257075  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inner CV selection summary (top rows):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>task</th>\n",
              "      <th>model_name</th>\n",
              "      <th>sampler</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.746032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.746032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.708791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.690273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.746032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.698413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.696825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.696825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>none</td>\n",
              "      <td>0.612698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>none</td>\n",
              "      <td>0.634921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>none</td>\n",
              "      <td>0.612698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>none</td>\n",
              "      <td>0.634921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>none</td>\n",
              "      <td>0.612698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>none</td>\n",
              "      <td>0.634921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.539683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.584127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.552381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.507937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.552381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>G3_vs_Rest</td>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>none</td>\n",
              "      <td>0.552381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.668043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.727887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>none</td>\n",
              "      <td>0.668043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.656396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.760294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.668043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>G4_vs_Rest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>none</td>\n",
              "      <td>0.652778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fold        task          model_name sampler  mean_test_score\n",
              "0      1  G3_vs_Rest  LogisticRegression    none         0.746032\n",
              "1      1  G3_vs_Rest  LogisticRegression    none         0.746032\n",
              "2      1  G3_vs_Rest  LogisticRegression    none         0.708791\n",
              "3      1  G3_vs_Rest  LogisticRegression    none         0.690273\n",
              "4      1  G3_vs_Rest                 SVM    none         0.746032\n",
              "5      1  G3_vs_Rest                 SVM    none         0.698413\n",
              "6      1  G3_vs_Rest                 SVM    none         0.696825\n",
              "7      1  G3_vs_Rest                 SVM    none         0.696825\n",
              "8      1  G3_vs_Rest        RandomForest    none         0.612698\n",
              "9      1  G3_vs_Rest        RandomForest    none         0.634921\n",
              "10     1  G3_vs_Rest        RandomForest    none         0.612698\n",
              "11     1  G3_vs_Rest        RandomForest    none         0.634921\n",
              "12     1  G3_vs_Rest        RandomForest    none         0.612698\n",
              "13     1  G3_vs_Rest        RandomForest    none         0.634921\n",
              "14     1  G3_vs_Rest    GradientBoosting    none         0.555556\n",
              "15     1  G3_vs_Rest    GradientBoosting    none         0.555556\n",
              "16     1  G3_vs_Rest    GradientBoosting    none         0.539683\n",
              "17     1  G3_vs_Rest    GradientBoosting    none         0.584127\n",
              "18     1  G3_vs_Rest    GradientBoosting    none         0.552381\n",
              "19     1  G3_vs_Rest    GradientBoosting    none         0.507937\n",
              "20     1  G3_vs_Rest    GradientBoosting    none         0.552381\n",
              "21     1  G3_vs_Rest    GradientBoosting    none         0.552381\n",
              "22     1  G4_vs_Rest  LogisticRegression    none         0.668043\n",
              "23     1  G4_vs_Rest  LogisticRegression    none         0.777778\n",
              "24     1  G4_vs_Rest  LogisticRegression    none         0.727887\n",
              "25     1  G4_vs_Rest  LogisticRegression    none         0.668043\n",
              "26     1  G4_vs_Rest                 SVM    none         0.656396\n",
              "27     1  G4_vs_Rest                 SVM    none         0.760294\n",
              "28     1  G4_vs_Rest                 SVM    none         0.668043\n",
              "29     1  G4_vs_Rest                 SVM    none         0.652778"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def require_file(path: Path, context: str):\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"{context}: expected file not found -> {path}\")\n",
        "    return path\n",
        "\n",
        "def find_latest_run_dir(base_dir: Path) -> Path:\n",
        "    if not base_dir.exists():\n",
        "        raise FileNotFoundError(f\"Run base directory missing: {base_dir}\")\n",
        "    candidates = [p for p in base_dir.iterdir() if p.is_dir()]\n",
        "    if not candidates:\n",
        "        raise FileNotFoundError(f\"No run directories found under: {base_dir}\")\n",
        "    return sorted(candidates, key=lambda p: p.stat().st_mtime)[-1]\n",
        "\n",
        "def load_metrics(run_dir: Path):\n",
        "    summary_json = run_dir / \"metrics_summary.json\"\n",
        "    if summary_json.exists():\n",
        "        return json.loads(summary_json.read_text(encoding=\"utf-8\"))\n",
        "    alt_csv = run_dir / \"metrics_outer_meta_eval.csv\"\n",
        "    if alt_csv.exists():\n",
        "        return {\"fallback_csv\": True, \"table\": pd.read_csv(alt_csv)}\n",
        "    raise FileNotFoundError(f\"No technical metrics artifact found in {run_dir}\")\n",
        "\n",
        "def load_predictions(run_dir: Path):\n",
        "    preds = sorted(run_dir.glob(\"fold*/binary_*/predictions_outer_test.csv\"))\n",
        "    if preds:\n",
        "        return pd.read_csv(preds[0])\n",
        "    return None\n",
        "\n",
        "def load_config(run_dir: Path):\n",
        "    resolved = run_dir / \"config.resolved.yaml\"\n",
        "    if resolved.exists():\n",
        "        return yaml.safe_load(resolved.read_text(encoding=\"utf-8\"))\n",
        "    run_manifest = run_dir / \"run.json\"\n",
        "    if run_manifest.exists():\n",
        "        return json.loads(run_manifest.read_text(encoding=\"utf-8\"))\n",
        "    raise FileNotFoundError(f\"No resolved config/run manifest found in {run_dir}\")\n",
        "\n",
        "def load_gate_results(project_dir: Path):\n",
        "    payload_path = project_dir / \"promotion\" / \"technical_gate_research_exploratory.json\"\n",
        "    if payload_path.exists():\n",
        "        return json.loads(payload_path.read_text(encoding=\"utf-8\"))\n",
        "    raise FileNotFoundError(\n",
        "        f\"Technical gate payload not found: {payload_path}. Run gate-evaluation cell first.\"\n",
        "    )\n",
        "\n",
        "def find_inner_cv_csv(run_dir: Path) -> Path:\n",
        "    candidates = [\n",
        "        run_dir / \"inner_cv_results.csv\",\n",
        "        run_dir / \"metrics_inner_cv.csv\",\n",
        "        run_dir / \"metrics_inner_cv_splits.csv\",\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    discovered = sorted(run_dir.glob(\"*inner*cv*.csv\"))\n",
        "    if discovered:\n",
        "        return discovered[0]\n",
        "    available_csv = [p.name for p in sorted(run_dir.glob(\"*.csv\"))]\n",
        "    raise FileNotFoundError(\n",
        "        f\"No inner-CV CSV found in {run_dir}. Available CSV files: {available_csv}\"\n",
        "    )\n",
        "\n",
        "metrics_payload = load_metrics(TECHNICAL_ALIAS)\n",
        "outer_csv = require_file(TECHNICAL_ALIAS / \"metrics_outer_meta_eval.csv\", \"Technical outer metrics\")\n",
        "inner_csv = find_inner_cv_csv(TECHNICAL_ALIAS)\n",
        "\n",
        "outer_df = pd.read_csv(outer_csv)\n",
        "outer_val = outer_df[outer_df.get(\"phase\", \"val\") == \"val\"].copy()\n",
        "inner_df = pd.read_csv(inner_csv)\n",
        "\n",
        "print(f\"Using inner CV file: {inner_csv.name}\")\n",
        "\n",
        "print(\"Technical metrics summary:\")\n",
        "if isinstance(metrics_payload, dict) and \"summary\" in metrics_payload:\n",
        "    display(pd.DataFrame([metrics_payload[\"summary\"]]))\n",
        "else:\n",
        "    print(\"metrics_summary.json unavailable; showing fallback table head\")\n",
        "    display(outer_val.head())\n",
        "\n",
        "print(\"Inner CV selection summary (top rows):\")\n",
        "cols_pref = [\"fold\", \"task\", \"model_name\", \"sampler\", \"mean_test_f1_macro\", \"mean_test_score\", \"rank_test_f1\"]\n",
        "cols = [c for c in cols_pref if c in inner_df.columns]\n",
        "if cols:\n",
        "    display(inner_df[cols].head(30))\n",
        "else:\n",
        "    print(\"Expected selection columns not found; showing first columns from inner CV table.\")\n",
        "    display(inner_df.head(30))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qw/wt3crg911d32djy9xk8j0q8r0000gn/T/ipykernel_74743/1991860611.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No saved confusion matrix image found in fold artifacts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qw/wt3crg911d32djy9xk8j0q8r0000gn/T/ipykernel_74743/1991860611.py:37: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n",
            "/var/folders/qw/wt3crg911d32djy9xk8j0q8r0000gn/T/ipykernel_74743/1991860611.py:47: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "plot_metrics = [\"f1_macro\", \"balanced_accuracy\", \"sensitivity\", \"specificity\", \"mcc\", \"roc_auc_ovr_macro\"]\n",
        "present = [m for m in plot_metrics if m in outer_val.columns]\n",
        "\n",
        "if present:\n",
        "    fig, ax = plt.subplots(figsize=(12, 5), constrained_layout=True)\n",
        "    x = np.arange(len(outer_val))\n",
        "    width = 0.12 if len(present) >= 5 else 0.18\n",
        "    for i, m in enumerate(present):\n",
        "        ax.bar(x + i * width, pd.to_numeric(outer_val[m], errors=\"coerce\"), width=width, label=m)\n",
        "    ax.set_title(\"Technical Validation Outer-Fold Metrics (Meta)\")\n",
        "    ax.set_xlabel(\"Outer Fold Row Index\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_ylim(0, 1.05)\n",
        "    ax.set_xticks(x + width * (len(present)-1) / 2)\n",
        "    ax.set_xticklabels([str(i + 1) for i in range(len(outer_val))])\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No expected key metrics found for plotting.\")\n",
        "\n",
        "cm_pngs = sorted(TECHNICAL_ALIAS.glob(\"fold*/binary_*/confusion_meta_fold*.png\"))\n",
        "if cm_pngs:\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(plt.imread(cm_pngs[0]))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Technical Confusion Matrix (example: {cm_pngs[0].name})\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No saved confusion matrix image found in fold artifacts.\")\n",
        "\n",
        "roc_avg = TECHNICAL_ALIAS / \"roc_meta_averaged.png\"\n",
        "if roc_avg.exists():\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(plt.imread(roc_avg))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Technical ROC (Averaged)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Averaged ROC plot not found.\")\n",
        "\n",
        "pr_avg = TECHNICAL_ALIAS / \"pr_meta_averaged.png\"\n",
        "if pr_avg.exists():\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(plt.imread(pr_avg))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Technical PR (Averaged)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Averaged PR plot not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Promotion Gate Evaluation â€” Technical (Research / Exploratory)\n",
        "\n",
        "This gate is computed against technical summary metrics only because no independent test set is available.\n",
        "\n",
        "**Research / Exploratory Gate (layman explanation):**\n",
        "The model shows promise and performs better than chance, but it is not yet considered clinically deployment-ready without independent-test confirmation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gate template: Research / Exploratory Gate\n",
            "Description: Lenient baseline gate for exploratory model development and research triage.\n",
            "Layman: The model shows promise and performs better than chance, but isn't ready for clinical use yet.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>op</th>\n",
              "      <th>threshold</th>\n",
              "      <th>observed_value</th>\n",
              "      <th>passed</th>\n",
              "      <th>aggregation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Balanced Accuracy</td>\n",
              "      <td>&gt;=</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.990741</td>\n",
              "      <td>True</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F1 Score</td>\n",
              "      <td>&gt;=</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.991475</td>\n",
              "      <td>True</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              metric  op  threshold  observed_value  passed aggregation\n",
              "0  Balanced Accuracy  >=       0.70        0.990741    True        mean\n",
              "1           F1 Score  >=       0.65        0.991475    True        mean"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Technical gate overall pass: True\n",
            "Independent-test gate status: NOT EVALUATED (no independent test dataset configured)\n",
            "Saved technical gate payload: runs/mrs_mb_meta_sklearn_technical/project/promotion/technical_gate_research_exploratory.json\n"
          ]
        }
      ],
      "source": [
        "template = get_promotion_gate_template(\"research_exploratory\")\n",
        "print(\"Gate template:\", template.display_name)\n",
        "print(\"Description:\", template.description)\n",
        "print(\"Layman:\", template.layman_explanation)\n",
        "\n",
        "summary = metrics_payload.get(\"summary\", {}) if isinstance(metrics_payload, dict) else {}\n",
        "\n",
        "# Fallback from outer val means if summary lacks fields\n",
        "for col in [\"f1_macro\", \"f1_weighted\", \"balanced_accuracy\", \"recall\", \"sensitivity\", \"mcc\"]:\n",
        "    if col not in summary and col in outer_val.columns:\n",
        "        summary[col] = float(pd.to_numeric(outer_val[col], errors=\"coerce\").mean())\n",
        "\n",
        "rows = []\n",
        "for gate in template.gates:\n",
        "    observed = resolve_metric(summary, gate.metric)\n",
        "    passed = (observed is not None) and (\n",
        "        observed >= gate.threshold if gate.op == \">=\" else\n",
        "        observed > gate.threshold if gate.op == \">\" else\n",
        "        observed <= gate.threshold if gate.op == \"<=\" else\n",
        "        observed < gate.threshold\n",
        "    )\n",
        "    rows.append({\n",
        "        \"metric\": gate.metric,\n",
        "        \"op\": gate.op,\n",
        "        \"threshold\": gate.threshold,\n",
        "        \"observed_value\": None if observed is None else float(observed),\n",
        "        \"passed\": bool(passed),\n",
        "        \"aggregation\": \"mean\",\n",
        "    })\n",
        "\n",
        "gate_table = pd.DataFrame(rows)\n",
        "display(gate_table)\n",
        "\n",
        "overall_pass = bool(gate_table[\"passed\"].all()) if not gate_table.empty else False\n",
        "print(\"Technical gate overall pass:\", overall_pass)\n",
        "print(\"Independent-test gate status: NOT EVALUATED (no independent test dataset configured)\")\n",
        "\n",
        "# Persist notebook-computed technical gate artifact\n",
        "payload = {\n",
        "    \"template_id\": template.template_id,\n",
        "    \"template_name\": template.display_name,\n",
        "    \"layman_explanation\": template.layman_explanation,\n",
        "    \"technical_only\": True,\n",
        "    \"independent_test_evaluated\": False,\n",
        "    \"technical_summary_metrics\": summary,\n",
        "    \"per_gate_results\": rows,\n",
        "    \"technical_overall_pass\": overall_pass,\n",
        "}\n",
        "out_path = PROJECT_DIR / \"promotion\" / \"technical_gate_research_exploratory.json\"\n",
        "out_path.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved technical gate payload:\", out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Artifact Review / Provenance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artifact_name</th>\n",
              "      <th>path</th>\n",
              "      <th>description</th>\n",
              "      <th>exists</th>\n",
              "      <th>loaded_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>project_config</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/project/pro...</td>\n",
              "      <td>Project configuration YAML</td>\n",
              "      <td>True</td>\n",
              "      <td>project, data, key_columns, task, validation, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thresholds</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/project/reg...</td>\n",
              "      <td>Promotion gate template config</td>\n",
              "      <td>True</td>\n",
              "      <td>technical_validation, independent_test, promot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>technical_run_manifest</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/technical/r...</td>\n",
              "      <td>Training manifest for technical run</td>\n",
              "      <td>True</td>\n",
              "      <td>run_id, timestamp, package_version, training_d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>technical_lineage</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/technical/l...</td>\n",
              "      <td>Run provenance and hashes</td>\n",
              "      <td>True</td>\n",
              "      <td>phase, run_id, timestamp_local, timestamp_utc,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>technical_metrics_summary</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/technical/m...</td>\n",
              "      <td>Aggregated technical metrics</td>\n",
              "      <td>True</td>\n",
              "      <td>summary, per_fold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>technical_outer_metrics</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/technical/m...</td>\n",
              "      <td>Per-fold outer validation metrics</td>\n",
              "      <td>True</td>\n",
              "      <td>rows&gt;= 5, cols=42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>inner_cv_results</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/technical/m...</td>\n",
              "      <td>Inner CV model-selection table (or closest ava...</td>\n",
              "      <td>True</td>\n",
              "      <td>rows&gt;= 5, cols=11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>resolved_config</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/technical/c...</td>\n",
              "      <td>Resolved config used for run</td>\n",
              "      <td>True</td>\n",
              "      <td>project, data, key_columns, task, validation, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>technical_gate_payload</td>\n",
              "      <td>runs/mrs_mb_meta_sklearn_technical/project/pro...</td>\n",
              "      <td>Technical-only gate evaluation artifact</td>\n",
              "      <td>True</td>\n",
              "      <td>template_id, template_name, layman_explanation...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               artifact_name  \\\n",
              "0             project_config   \n",
              "1                 thresholds   \n",
              "2     technical_run_manifest   \n",
              "3          technical_lineage   \n",
              "4  technical_metrics_summary   \n",
              "5    technical_outer_metrics   \n",
              "6           inner_cv_results   \n",
              "7            resolved_config   \n",
              "8     technical_gate_payload   \n",
              "\n",
              "                                                path  \\\n",
              "0  runs/mrs_mb_meta_sklearn_technical/project/pro...   \n",
              "1  runs/mrs_mb_meta_sklearn_technical/project/reg...   \n",
              "2  runs/mrs_mb_meta_sklearn_technical/technical/r...   \n",
              "3  runs/mrs_mb_meta_sklearn_technical/technical/l...   \n",
              "4  runs/mrs_mb_meta_sklearn_technical/technical/m...   \n",
              "5  runs/mrs_mb_meta_sklearn_technical/technical/m...   \n",
              "6  runs/mrs_mb_meta_sklearn_technical/technical/m...   \n",
              "7  runs/mrs_mb_meta_sklearn_technical/technical/c...   \n",
              "8  runs/mrs_mb_meta_sklearn_technical/project/pro...   \n",
              "\n",
              "                                         description  exists  \\\n",
              "0                         Project configuration YAML    True   \n",
              "1                     Promotion gate template config    True   \n",
              "2                Training manifest for technical run    True   \n",
              "3                          Run provenance and hashes    True   \n",
              "4                       Aggregated technical metrics    True   \n",
              "5                  Per-fold outer validation metrics    True   \n",
              "6  Inner CV model-selection table (or closest ava...    True   \n",
              "7                       Resolved config used for run    True   \n",
              "8            Technical-only gate evaluation artifact    True   \n",
              "\n",
              "                                      loaded_summary  \n",
              "0  project, data, key_columns, task, validation, ...  \n",
              "1  technical_validation, independent_test, promot...  \n",
              "2  run_id, timestamp, package_version, training_d...  \n",
              "3  phase, run_id, timestamp_local, timestamp_utc,...  \n",
              "4                                  summary, per_fold  \n",
              "5                                  rows>= 5, cols=42  \n",
              "6                                  rows>= 5, cols=11  \n",
              "7  project, data, key_columns, task, validation, ...  \n",
              "8  template_id, template_name, layman_explanation...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inner-CV artifact used: metrics_inner_cv.csv\n",
            "Effective config (from technical artifact):\n",
            "project:\n",
            "  id: MRS_MB_META_TECH\n",
            "  name: MRS MB Meta Technical\n",
            "  description: Reviewer notebook technical-validation-only run\n",
            "  owner: local\n",
            "data:\n",
            "  train:\n",
            "    manifest: /Users/alex/Documents/project-MLSubtype/data/MBmerged-z-scores_MLready_correction.csv\n",
            "key_columns:\n",
            "  label: MOLECULAR\n",
            "task:\n",
            "  mode: meta\n",
            "  patient_stratified: false\n",
            "validation:\n",
            "  nested_cv:\n",
            "    outer_folds: 3\n",
            "    inner_folds: 3\n",
            "    repeats: 1\n",
            "    seed: 42\n",
            "models:\n",
            "  candidates:\n",
            "  - logistic_regression\n",
            "  - svm\n",
            "  - random_forest\n",
            "  selection_metric: f1\n",
            "  selection_direction: max\n",
            "imbalance:\n",
            "  smote:\n",
            "    enabled: false\n",
            "    compare: false\n",
            "multiclass:\n",
            "  group_stratify: true\n",
            "  sklearn:\n",
            "    logreg:\n",
            "      solver: saga\n",
            "      multi_class: auto\n",
            "      penalty: l2\n",
            "      max_iter: 5000\n",
            "      tol: 0.001\n",
            "      C: 1.0\n",
            "      class_weight: balanced\n",
            "      n_jobs: -1\n",
            "metrics:\n",
            "  primary:\n",
            "  - f1\n",
            "  - balanced_accuracy\n",
            "  averaging: macro\n",
            "  include_confidence_intervals: false\n",
            "calibration:\n",
            "  enabled: 'true'\n",
            "  method: sigmoid\n",
            "  cv: 3\n",
            "  bins: 10\n",
            "  binning: uniform\n",
            "  isotonic_min_samples: 100\n",
            "  policy:\n",
            "    apply_to_modes:\n",
            "    - meta\n",
            "    force_keep: false\n",
            "    thresholds:\n",
            "      underconfidence_gap: -0.1\n",
            "      high_accuracy: 0.9\n",
            "      near_perfect_accuracy: 0.97\n",
            "      min_calibration_n: 200\n",
            "      min_class_n: 25\n",
            "      min_brier_improvement: 0.002\n",
            "      max_log_loss_regression: 0.01\n",
            "      max_ece_ovr_regression: 0.01\n",
            "final_model:\n",
            "  sanity_min_std: 0.02\n",
            "  sanity_max_mean_deviation: 0.15\n",
            "  train_from_scratch: true\n",
            "  verify_dataset_hash: true\n",
            "bundle:\n",
            "  name: model_bundle\n",
            "  include_preprocessing: true\n",
            "  format: zip\n",
            "execution:\n",
            "  engine: sklearn\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def summarize_loaded(path: Path):\n",
        "    try:\n",
        "        if path.suffix in {\".json\", \".yaml\", \".yml\"}:\n",
        "            text = path.read_text(encoding=\"utf-8\")\n",
        "            data = json.loads(text) if path.suffix == \".json\" else yaml.safe_load(text)\n",
        "            if isinstance(data, dict):\n",
        "                return \", \".join(list(data.keys())[:8])\n",
        "            return f\"type={type(data).__name__}\"\n",
        "        if path.suffix == \".csv\":\n",
        "            df = pd.read_csv(path, nrows=5)\n",
        "            return f\"rows>= {len(df)}, cols={len(df.columns)}\"\n",
        "        return \"binary/non-tabular\"\n",
        "    except Exception as exc:\n",
        "        return f\"load error: {exc}\"\n",
        "\n",
        "def pick_existing(*paths: Path):\n",
        "    for p in paths:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "# Meta runs may use metrics_inner_cv.csv instead of inner_cv_results.csv\n",
        "inner_cv_artifact = pick_existing(\n",
        "    TECHNICAL_ALIAS / \"inner_cv_results.csv\",\n",
        "    TECHNICAL_ALIAS / \"metrics_inner_cv.csv\",\n",
        "    TECHNICAL_ALIAS / \"metrics_inner_cv_splits.csv\",\n",
        ")\n",
        "\n",
        "# Optional helper for discovery visibility\n",
        "available_csv = [p.name for p in sorted(TECHNICAL_ALIAS.glob(\"*.csv\"))]\n",
        "\n",
        "artifacts = [\n",
        "    (\"project_config\", PROJECT_DIR / \"project.yaml\", \"Project configuration YAML\"),\n",
        "    (\"thresholds\", PROJECT_DIR / \"registry\" / \"thresholds.yaml\", \"Promotion gate template config\"),\n",
        "    (\"technical_run_manifest\", TECHNICAL_ALIAS / \"run.json\", \"Training manifest for technical run\"),\n",
        "    (\"technical_lineage\", TECHNICAL_ALIAS / \"lineage.json\", \"Run provenance and hashes\"),\n",
        "    (\"technical_metrics_summary\", TECHNICAL_ALIAS / \"metrics_summary.json\", \"Aggregated technical metrics\"),\n",
        "    (\"technical_outer_metrics\", TECHNICAL_ALIAS / \"metrics_outer_meta_eval.csv\", \"Per-fold outer validation metrics\"),\n",
        "    (\n",
        "        \"inner_cv_results\",\n",
        "        inner_cv_artifact if inner_cv_artifact is not None else (TECHNICAL_ALIAS / \"inner_cv_results.csv\"),\n",
        "        \"Inner CV model-selection table (or closest available inner-CV artifact)\",\n",
        "    ),\n",
        "    (\"resolved_config\", TECHNICAL_ALIAS / \"config.resolved.yaml\", \"Resolved config used for run\"),\n",
        "    (\"technical_gate_payload\", PROJECT_DIR / \"promotion\" / \"technical_gate_research_exploratory.json\", \"Technical-only gate evaluation artifact\"),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for name, path, desc in artifacts:\n",
        "    rows.append({\n",
        "        \"artifact_name\": name,\n",
        "        \"path\": str(path),\n",
        "        \"description\": desc,\n",
        "        \"exists\": path.exists(),\n",
        "        \"loaded_summary\": summarize_loaded(path) if path.exists() else \"missing\",\n",
        "    })\n",
        "\n",
        "display(pd.DataFrame(rows))\n",
        "\n",
        "if inner_cv_artifact is None:\n",
        "    print(\"No inner-CV artifact found. Available CSV files in technical dir:\")\n",
        "    print(available_csv)\n",
        "else:\n",
        "    print(f\"Inner-CV artifact used: {inner_cv_artifact.name}\")\n",
        "\n",
        "print(\"Effective config (from technical artifact):\")\n",
        "cfg = load_config(TECHNICAL_ALIAS)\n",
        "if isinstance(cfg, dict):\n",
        "    print(yaml.safe_dump(cfg, sort_keys=False)[:5000])\n",
        "else:\n",
        "    print(type(cfg))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusions for Reviewers\n",
        "\n",
        "This notebook reproduced a full **technical validation** pipeline for MB molecular group classification from MR spectroscopy using Classiflow meta mode on sklearn. It produced nested-CV artifacts, fold-level and aggregate metrics, and provenance files (`run.json`, `lineage.json`, resolved config, and CV tables/plots).\n",
        "\n",
        "Promotion was assessed with the **Research / Exploratory Gate** using technical metrics only. Because no independent test dataset is configured, this notebook explicitly reports technical status as exploratory evidence and does not claim independent-test confirmation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
