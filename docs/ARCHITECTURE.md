# classiflow Architecture

## High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   CLI (Typer)        â”‚  Python API          â”‚  Streamlit UI     â”‚
â”‚   classiflow train-*  â”‚  TrainConfig         â”‚  app.py + pages/  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Core Training Pipeline                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  train_binary_task() / train_meta_classifier()           â”‚  â”‚
â”‚  â”‚  â€¢ Load & validate data                                  â”‚  â”‚
â”‚  â”‚  â€¢ Build tasks (OvR, pairwise, composite)                â”‚  â”‚
â”‚  â”‚  â€¢ Run nested CV with orchestrator                       â”‚  â”‚
â”‚  â”‚  â€¢ Save artifacts & metrics                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Nested CV Orchestrator                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Outer CV (Validation)          Inner CV (Hyperparameters)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ For each fold:       â”‚      â”‚ GridSearchCV with:   â”‚         â”‚
â”‚  â”‚ â€¢ Split train/val    â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ â€¢ Multi-metric      â”‚         â”‚
â”‚  â”‚ â€¢ Train models       â”‚      â”‚ â€¢ SMOTE variants    â”‚         â”‚
â”‚  â”‚ â€¢ Evaluate on val    â”‚      â”‚ â€¢ Best param search â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Tasks      â”‚  â”‚   Models     â”‚  â”‚   Metrics    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ TaskBuilder  â”‚  â”‚ Estimators   â”‚  â”‚ Binary       â”‚
    â”‚ â€¢ OvR        â”‚  â”‚ â€¢ LogReg     â”‚  â”‚ â€¢ Accuracy   â”‚
    â”‚ â€¢ Pairwise   â”‚  â”‚ â€¢ SVM        â”‚  â”‚ â€¢ F1 Score   â”‚
    â”‚ â€¢ Composite  â”‚  â”‚ â€¢ RF/GB      â”‚  â”‚ â€¢ ROC AUC    â”‚
    â”‚ JSON loading â”‚  â”‚ AdaptiveSMOTEâ”‚  â”‚ â€¢ MCC        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Module Dependency Graph

```
classiflow/
â”‚
â”œâ”€â”€ config.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   (TrainConfig, MetaConfig)        â”‚
â”‚                                    â”‚
â”œâ”€â”€ io/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   â”œâ”€â”€ loaders.py                   â”‚
â”‚   â””â”€â”€ schema.py                    â”‚
â”‚                                    â”‚
â”œâ”€â”€ tasks/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   â”œâ”€â”€ builder.py                   â”‚
â”‚   â””â”€â”€ composite.py                 â”‚
â”‚                                    â”‚
â”œâ”€â”€ models/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   â”œâ”€â”€ estimators.py                â”‚
â”‚   â””â”€â”€ smote.py                     â”‚
â”‚                                    â”‚
â”œâ”€â”€ metrics/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   â”œâ”€â”€ binary.py                    â”‚
â”‚   â””â”€â”€ scorers.py                   â”‚
â”‚                                    â”‚
â”‚       â–²  â–²  â–²  â–²  â–²  â–²             â”‚
â”‚       â”‚  â”‚  â”‚  â”‚  â”‚  â”‚             â”‚
â”‚       â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜             â”‚
â”‚                                    â”‚
â”œâ”€â”€ training/ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   â”œâ”€â”€ nested_cv.py    (uses all above)
â”‚   â”œâ”€â”€ binary.py       (uses nested_cv)
â”‚   â””â”€â”€ meta.py         (uses nested_cv + tasks)
â”‚           â”‚
â”‚           â–¼
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ saver.py
â”‚   â””â”€â”€ loader.py
â”‚           â”‚
â”‚           â–¼
â”œâ”€â”€ cli/
â”‚   â””â”€â”€ main.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ training/*
â”‚           â”‚
â”‚           â–¼
â””â”€â”€ streamlit_app/
    â”œâ”€â”€ app.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ training/*
    â””â”€â”€ pages/
        â””â”€â”€ 01_Train_Models.py
```

## Data Flow: Meta-Classifier Training

```
1. User Input
   â”œâ”€ data.csv (features + labels)
   â”œâ”€ tasks.json (optional composite tasks)
   â””â”€ config (folds, SMOTE, seed, etc.)
                â”‚
                â–¼
2. Load & Validate Data
   â”œâ”€ io.loaders.load_data()
   â”œâ”€ io.loaders.validate_data()
   â””â”€ io.schema.DataSchema.from_data()
                â”‚
                â–¼
3. Build Tasks
   â”œâ”€ tasks.builder.TaskBuilder(classes)
   â”‚  â”œâ”€ .build_ovr_tasks()          â†’ {A_vs_Rest, B_vs_Rest, ...}
   â”‚  â””â”€ .build_pairwise_tasks()     â†’ {A_vs_B, A_vs_C, ...}
   â””â”€ tasks.composite.load_composite_tasks(json_path)
                â”‚                      â†’ {Custom_Task_1, ...}
                â–¼
4. Nested CV Loop (Outer Folds)
   For each outer_fold in [1, 2, 3]:
      â”œâ”€ Split: train_idx, val_idx
      â”‚
      â”œâ”€ For each SMOTE variant in [smote, none]:
      â”‚    â”‚
      â”‚    â”œâ”€ Train Binary Tasks (Inner CV)
      â”‚    â”‚   For each task in tasks:
      â”‚    â”‚      â”œâ”€ Extract binary labels: y_bin = task(y_train)
      â”‚    â”‚      â”œâ”€ For each model in [LogReg, SVM, RF, GB]:
      â”‚    â”‚      â”‚    â”œâ”€ Build pipeline: [SMOTE?, VarThreshold, Scaler, Estimator]
      â”‚    â”‚      â”‚    â”œâ”€ GridSearchCV with inner CV (RepeatedStratifiedKFold)
      â”‚    â”‚      â”‚    â”‚    â””â”€ Multi-metric: [Acc, Prec, F1, MCC, Sens, Spec, AUC, BAcc]
      â”‚    â”‚      â”‚    â”œâ”€ Select best params (refit on F1)
      â”‚    â”‚      â”‚    â””â”€ Evaluate on train & val
      â”‚    â”‚      â””â”€ Select best model per task (highest F1)
      â”‚    â”‚
      â”‚    â”œâ”€ Build Meta-Features
      â”‚    â”‚    For each task:
      â”‚    â”‚       â”œâ”€ Get best binary model for task
      â”‚    â”‚       â”œâ”€ Extract scores: scores = model.predict_proba(X)[:, 1]
      â”‚    â”‚       â””â”€ Create meta-feature column: task_score
      â”‚    â”‚    Result: X_meta = [task1_score, task2_score, ..., taskN_score]
      â”‚    â”‚
      â”‚    â””â”€ Train Meta-Classifier
      â”‚         â”œâ”€ Model: LogisticRegression(multi_class='multinomial')
      â”‚         â”œâ”€ GridSearchCV for C hyperparameter
      â”‚         â”œâ”€ Fit: meta_model.fit(X_meta_train, y_train)
      â”‚         â”œâ”€ Predict: y_pred = meta_model.predict(X_meta_val)
      â”‚         â””â”€ Evaluate: accuracy, f1_macro, f1_weighted, ROC AUC
      â”‚
      â””â”€ Save Fold Artifacts
           â”œâ”€ fold{N}/binary_{variant}/binary_pipes.joblib
           â”œâ”€ fold{N}/binary_{variant}/meta_model.joblib
           â”œâ”€ fold{N}/binary_{variant}/meta_features.csv
           â””â”€ fold{N}/binary_{variant}/meta_classes.csv
                â”‚
                â–¼
5. Aggregate & Export
   â”œâ”€ metrics_inner_cv.csv               (all GridSearchCV candidates)
   â”œâ”€ metrics_inner_cv_splits.{csv,xlsx} (per-split metrics for best params)
   â”œâ”€ metrics_outer_binary_eval.csv      (binary task train/val metrics)
   â”œâ”€ metrics_outer_meta_eval.csv        (meta-classifier train/val metrics)
   â””â”€ run_manifest.json                  (config + git hash + timestamp)
                â”‚
                â–¼
6. Output
   â”œâ”€ Trained models in fold{N}/
   â”œâ”€ Metrics CSVs for analysis
   â”œâ”€ Reproducibility manifest
   â””â”€ Ready for:
      â”œâ”€ Inference (load models + predict on new data)
      â”œâ”€ Summarization (aggregate CV metrics)
      â”œâ”€ Visualization (ROC, confusion, calibration)
      â””â”€ Publication (tables, figures, supplementary data)
```

## Adaptive SMOTE Flow

```
Pipeline: [AdaptiveSMOTE, VarianceThreshold, StandardScaler, Estimator]
                â”‚
                â–¼
AdaptiveSMOTE.fit_resample(X_train, y_train):
    â”‚
    â”œâ”€ Check: Is y_train binary (0/1)?
    â”‚   â”œâ”€ No  â†’ Pass through (X_train, y_train)
    â”‚   â””â”€ Yes â†’ Continue
    â”‚
    â”œâ”€ Count minority class: minority = min(y_train.value_counts())
    â”‚
    â”œâ”€ Check: minority > 1?
    â”‚   â”œâ”€ No  â†’ Pass through (too few samples)
    â”‚   â””â”€ Yes â†’ Continue
    â”‚
    â”œâ”€ Adapt k_neighbors: k = max(1, min(k_max, minority - 1))
    â”‚
    â”œâ”€ Apply SMOTE: sm = SMOTE(k_neighbors=k)
    â”‚                X_res, y_res = sm.fit_resample(X_train, y_train)
    â”‚
    â””â”€ Return: (X_res, y_res) with balanced classes
```

## CLI â†’ Library Call Chain

```
$ classiflow train-meta --data-csv data.csv --label-col subtype --smote both

    â”‚
    â–¼
cli/main.py:train_meta()
    â”‚
    â”œâ”€ Parse arguments
    â”œâ”€ Build MetaConfig(data_csv, label_col, smote_mode='both', ...)
    â”‚
    â””â”€ Call: training.train_meta_classifier(config)
              â”‚
              â–¼
         training/meta.py:train_meta_classifier(config)
              â”‚
              â”œâ”€ Load data: io.load_data()
              â”œâ”€ Build tasks: tasks.TaskBuilder(...).build_all_auto_tasks()
              â”‚
              â””â”€ Call: _run_meta_nested_cv(X, y, tasks, config)
                    â”‚
                    â”œâ”€ Outer CV: StratifiedKFold.split(X, y)
                    â”‚
                    â””â”€ For each fold:
                          â”‚
                          â”œâ”€ Train binary tasks: _train_binary_tasks(...)
                          â”‚     â”‚
                          â”‚     â””â”€ Uses: models.get_estimators()
                          â”‚               models.AdaptiveSMOTE()
                          â”‚               metrics.get_scorers()
                          â”‚               sklearn.GridSearchCV
                          â”‚
                          â”œâ”€ Build meta-features: _build_meta_features(...)
                          â”‚
                          â”œâ”€ Train meta-model: _train_meta_model(...)
                          â”‚
                          â””â”€ Save artifacts: artifacts.save_*()
```

## Backward Compatibility Layer

```
Legacy Streamlit Page (pages/01_Train_Models.py)
    â”‚
    â”œâ”€ Import: from utils.wrappers import run_train_meta_classifier
    â”‚
    â””â”€ Call: run_train_meta_classifier(root, csv_path, tasks_json, ...)
                â”‚
                â–¼
         utils/compat.py:run_train_meta_classifier()
                â”‚
                â”œâ”€ Emit DeprecationWarning
                â”‚
                â”œâ”€ Check: Is classiflow package installed?
                â”‚   â”‚
                â”‚   â”œâ”€ Yes â†’ Build MetaConfig â†’ Call classiflow.train_meta_classifier()
                â”‚   â”‚
                â”‚   â””â”€ No  â†’ Fallback: subprocess.run(scripts/train_binary_meta_classifier.py)
                â”‚
                â””â”€ Return results
```

## Key Design Patterns

### 1. **Separation of Concerns**
- **Config**: Dataclasses (config.py)
- **I/O**: Loading + validation (io/)
- **Logic**: Training orchestration (training/)
- **Persistence**: Artifacts save/load (artifacts/)
- **UI**: CLI + Streamlit (cli/, streamlit_app/)

### 2. **Dependency Injection**
- Pass `config` objects instead of scattered arguments
- Pass estimators/scorers/tasks as dictionaries
- Configurable via constructor or factory functions

### 3. **Builder Pattern**
- `TaskBuilder`: Fluent API for constructing tasks
  ```python
  builder = TaskBuilder(classes)
      .build_ovr_tasks()
      .build_pairwise_tasks()
      .add_composite_task("Custom", pos, neg)
  tasks = builder.get_tasks()
  ```

### 4. **Strategy Pattern**
- SMOTE variants: `"off"`, `"on"`, `"both"` â†’ different samplers
- Model selection: Dictionary of estimators + param grids

### 5. **Adapter Pattern**
- `AdaptiveSMOTE`: Adapts SMOTE to work with GridSearchCV
- Implements `fit_resample()` compatible with imblearn.Pipeline

### 6. **Facade Pattern**
- `train_binary_task(config)`: High-level API hides complexity
- `train_meta_classifier(config)`: High-level API for meta pipeline

---

## Testing Strategy

```
Unit Tests (tests/unit/)
â”œâ”€â”€ test_tasks.py          â†’ TaskBuilder logic
â”œâ”€â”€ test_smote.py          â†’ AdaptiveSMOTE behavior
â””â”€â”€ test_metrics.py        â†’ Binary metrics computation

Integration Tests (future)
â””â”€â”€ test_workflows.py      â†’ Full training + inference pipelines

Fixtures (tests/conftest.py)
â”œâ”€â”€ sample_binary_data     â†’ 100 samples, 20 features, 2 classes
â”œâ”€â”€ sample_multiclass_data â†’ 150 samples, 20 features, 3 classes
â””â”€â”€ temp_outdir            â†’ Temporary directory for outputs
```

---

## Production Considerations

### âœ… Implemented

1. **Type Safety**: Dataclasses + type hints
2. **Logging**: Structured logging (not print)
3. **Error Handling**: Validation + meaningful errors
4. **Determinism**: Fixed seeds, run manifests
5. **Documentation**: Docstrings + README + guides
6. **Testing**: Unit tests with fixtures
7. **Packaging**: pyproject.toml + src/ layout
8. **Versioning**: Semantic versioning (0.1.0)
9. **Licensing**: MIT license
10. **Citation**: CITATION.cff for academic use

### ðŸ”„ Future Work

1. **Inference Pipeline**: Load models + predict on new data
2. **Plotting**: ROC curves, confusion matrices, calibration
3. **Summarization**: Aggregate CV metrics across folds
4. **Export**: Best task spreadsheets
5. **Integration Tests**: End-to-end workflows
6. **CI/CD**: GitHub Actions pipeline
7. **Performance**: Parallel processing, caching
8. **Extended Docs**: Tutorials, API reference

---

## Summary

The architecture is:
- **Modular**: Clear boundaries between components
- **Testable**: Unit tests for core logic
- **Extensible**: Easy to add models, metrics, tasks
- **Maintainable**: Type hints, docstrings, logging
- **Production-Ready**: Packaging, versioning, documentation

**Ready for PyPI publication and academic citation! ðŸš€**
